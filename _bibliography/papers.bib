---
---

@article{westny2023evaluation,
  title={Evaluation of Differentially Constrained Motion Models for Graph-Based Trajectory Prediction},
  author={Westny, Theodor and Oskarsson, Joel and Olofsson, Bj{\"o}rn and Frisk, Erik},
  journal={arXiv preprint arXiv:2304.05116},
  year={2023},
  abstract = {Given their flexibility and encouraging performance, deep-learning models are becoming standard for motion prediction in autonomous driving. However, with great flexibility comes a lack of interpretability and possible violations of physical constraints. Accompanying these data-driven methods with differentially-constrained motion models to provide physically feasible trajectories is a promising future direction. The foundation for this work is a previously introduced graph-neural-network-based model, MTP-GO. The neural network learns to compute the inputs to an underlying motion model to provide physically feasible trajectories. This research investigates the performance of various motion models in combination with numerical solvers for the prediction task. The study shows that simpler models, such as low-order integrator models, are preferred over more complex, e.g., kinematic models, to achieve accurate predictions. Further, the numerical solver can have a substantial impact on performance, advising against commonly used first-order methods like Euler forward. Instead, a second-order method like Heun's can greatly improve predictions.},
  bibtex_show={true},
  pdf = {https://arxiv.org/pdf/2304.05116},
  code = {https://github.com/westny/mtp-go},
  preview = {thumb_evaluation_diff.png},
}

@InProceedings{tgnn4i,
  title = 	 {Temporal Graph Neural Networks for Irregular Data},
  author =       {Oskarsson, Joel and Sid\'en, Per and Lindsten, Fredrik},
  booktitle = 	 {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {4515--4531},
  year = 	 {2023},
  editor = 	 {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},
  volume = 	 {206},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  bibtex_show={true},
  pdf = 	 {https://proceedings.mlr.press/v206/oskarsson23a/oskarsson23a.pdf},
  abstract = 	 {This paper proposes a temporal graph neural network model for forecasting of graph-structured irregularly observed time series. Our TGNN4I model is designed to handle both irregular time steps and partial observations of the graph. This is achieved by introducing a time-continuous latent state in each node, following a linear Ordinary Differential Equation (ODE) defined by the output of a Gated Recurrent Unit (GRU). The ODE has an explicit solution as a combination of exponential decay and periodic dynamics. Observations in the graph neighborhood are taken into account by integrating graph neural network layers in both the GRU state update and predictive model. The time-continuous dynamics additionally enable the model to make predictions at arbitrary time steps. We propose a loss function that leverages this and allows for training the model for forecasting over different time horizons. Experiments on simulated data and real-world data from traffic and climate modeling validate the usefulness of both the graph structure and time-continuous dynamics in settings with irregular observations.},
  code = {https://github.com/joeloskarsson/tgnn4i},
  preview = {thumb_periodic_tgnn.png},
  poster = {AISTATS_poster_tgnn4i.pdf},
  slides = {TGNN4I_AISTATS_presentation.pdf},
  video = {https://www.youtube.com/watch?v=r0mpZjUnpHA},
  selected={true},
}

@article{westny2023graph,
  title="{MTP-GO: G}raph-Based Probabilistic Multi-Agent Trajectory Prediction with Neural {ODE}s",
  author={Westny, Theodor and Oskarsson, Joel and Olofsson, Bj{\"o}rn and Frisk, Erik},
  journal={arXiv preprint arXiv:2302.00735},
  year={2023},
  abstract = {Enabling resilient autonomous motion planning requires robust predictions of surrounding road users' future behavior. In response to this need and the associated challenges, we introduce our model, titled MTP-GO. The model encodes the scene using temporal graph neural networks to produce the inputs to an underlying motion model. The motion model is implemented using neural ordinary differential equations where the state-transition functions are learned with the rest of the model. Multi-modal probabilistic predictions are provided by combining the concept of mixture density networks and Kalman filtering. The results illustrate the predictive capabilities of the proposed model across various data sets, outperforming several state-of-the-art methods on a number of metrics.},
  bibtex_show={true},
  pdf = {https://arxiv.org/pdf/2302.00735},
  code = {https://github.com/westny/mtp-go},
  preview = {thumb_round.png},
}

@InProceedings{pmlr-v162-oskarsson22a,
  bibtex_show={true},
  title = 	 {Scalable Deep {G}aussian {M}arkov Random Fields for General Graphs},
  author =       {Oskarsson, Joel and Sid{\'e}n, Per and Lindsten, Fredrik},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {17117--17137},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/oskarsson22a/oskarsson22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/oskarsson22a.html},
  abstract = 	 {Machine learning methods on graphs have proven useful in many applications due to their ability to handle generally structured data. The framework of Gaussian Markov Random Fields (GMRFs) provides a principled way to define Gaussian models on graphs by utilizing their sparsity structure. We propose a flexible GMRF model for general graphs built on the multi-layer structure of Deep GMRFs, originally proposed for lattice graphs only. By designing a new type of layer we enable the model to scale to large graphs. The layer is constructed to allow for efficient training using variational inference and existing software frameworks for Graph Neural Networks. For a Gaussian likelihood, close to exact Bayesian inference is available for the latent field. This allows for making predictions with accompanying uncertainty estimates. The usefulness of the proposed model is verified by experiments on a number of synthetic and real world datasets, where it compares favorably to other both Bayesian and deep learning methods.},
  code = {https://github.com/joeloskarsson/graph-dgmrf},
  poster = {graph_dgmrf_poster.pdf},
  slides = {icml22_slides_graph_dgmrf.pdf},
  video = {https://icml.cc/virtual/2022/spotlight/17282},
  preview = {thumb_graph_dgmrf.png},
  selected={true},
}

